{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    " - <a href=\"#Table-of-Contents\">Table of Contents</a>\n",
    " - <a href=\"#Introduction\">Introduction</a>\n",
    " - <a href=\"#One-Dimensional-Quantum-Mechanics-Setup\">One-Dimensional Quantum Mechanics Setup</a>\n",
    " - <a href=\"#Periodicity-Gives-Quantization-Conditions\">Periodicity Gives Quantization Conditions</a>\n",
    " - <a href=\"#The-S-Matrix\">The S Matrix</a>\n",
    " - <a href=\"#Quantization-Condition-for-the-Relative-Wavefunction\">Quantization Condition for the Relative Wavefunction<a/>\n",
    " - <a href=\"#Aside:-A-More-Grown-Up-Derivation-via-the-T-Matrix\">Aside: A More Grown-Up Derivation via the T Matrix</a>\n",
    " - <a href=\"#Recap-before-Numerics\">Recap before Numerics</a>\n",
    " - <a href=\"#Discretization\">Discretization</a>\n",
    " - <a href=\"#Applying-Lüscher's-Finite-Volume-Formula\">Applying Lüscher's Finite Volume Formula</a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QCD is, of course, the theory of quarks and gluons.  At high energies the precision with which it can describe mesons and their properties is essential for understanding experimental signals, such as collider signals at the LHC.\n",
    "\n",
    "In contrast, the low-energy sector of QCD–––the sector of protons, neutrons, and their interactions–––is much more poorly understood.  Or, rather, the precision with which we can extract numbers about nuclear physics from QCD remains much more limited–––there still exist theories of nuclear physics that are not quantitatively grounded in the Standard Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last decade or so the single-nucleon sector has come under excellent control.  The nucleon masses and the proton-neutron mass splitting have been determined at the physical point, in the continuum limit, for example.  A steady march towards precision single-nucleon matrix elements is under way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you leave the single-nucleon sector, however, the field is much less developed.  However, multinucleon physics is interesting for a variety of experimental programs, such as low-energy underground BSM and neutrino experiments.  The targets in these experiments are not single nucleons but rather atomic nuclei.  So to interpret any signal from these experiments as constraints on new physics requires disentangling all the effects of many-body nuclear physics and QCD to pull out whatever may be new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QCD is also, obviously, the foundation on top of which nuclear physics, in principle, is built.  However, making this connection quantitative has remained an outstanding problem since it became clear QCD was, in fact, the theory of the strong nuclear force.\n",
    "\n",
    "The simplest multi-nucleon sector is the two nucleon sector.  Here, the simplest observables include the binding energies of any bound states and the scattering phase shifts.  We still lack a determination of these quantities from QCD at physical pion masses; at heavier pion masses there are still no calculations in the continuum limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scattering is a real-time process.  It also formally relies on asymptotically separated states.  However, on the lattice, typically we have neither: we usually work in Euclidean time to have a well-defined probability measure and we work in a finite volume so that our calculations require a finite amount of RAM and a finite amount of execution time.  There is a no-go theorem due to Maiani and Testa ([PLB **245**, 585 (1990)](https://doi.org/10.1016/0370-2693(90)90695-3)) that seemingly prevented access to scattering observables.\n",
    "\n",
    "However, Lüscher taught us (Commun. Math. Phys [104](https://doi.org/10.1007/BF01211589) and [105](https://doi.org/10.1007/BF01211097) (1986), [Nucl. Phys. B354 (1991) 531-578](https://doi.org/10.1016/0550-3213(91)90366-6), [Nucl. Phys. B364 (1991) 237-251](https://doi.org/10.1016/0550-3213(91)90584-K)) how to turn these seeming limitations to our advantage.  He provided a map from the finite volume spectrum (which can be determined in Euclidean time–––or real time, if you happen to have a method to do so!) to the infinite-volume phase shifts at those energies that appear in that finite volume.  Then, by changing the volume we work in we can change the allowed energies and fill in the phase shifts as a function of momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since those seminal works, there has been an enormous amount of theoretical progress, generalizing to moving frames, matrix elements, inelastic processes, the three-body case, and more.\n",
    "\n",
    "See, for example,\n",
    "\n",
    " - Wiese [Nucl. Phys. Proc. Suppl. 9 (1989) 609-613](https://doi.org/10.1016/0920-5632(89)90171-0)\n",
    " - Gottlieb and Rummukainen [Nucl. Phys. Proc. Suppl 47 (1996) 819-822](https://doi.org/10.1016/0920-5632(96)00182-X)\n",
    " - Hansen and Sharpe [PRD 86 (2012) 016007](https://doi.org/10.1103/PhysRevD.86.016007)\n",
    " - Briceño and Davoudi [PRD 87 (2013) 9 094507](https://doi.org/10.1103/PhysRevD.87.094507) and [PRD 88 (2013) 9 094507](https://doi.org/10.1103/PhysRevD.88.094507)\n",
    " - Briceño, Davoudi, and Luu [PRD 88 (2013) 3 034502](https://doi.org/10.1103/PhysRevD.88.034502)\n",
    " - Briceño, Davoudi, Luu, and Savage [PRD 88 (2013) 11 114507](https://doi.org/10.1103/PhysRevD.88.114507) and [PRD 89 (2014) 7 074509](https://doi.org/10.1103/PhysRevD.89.074509)\n",
    " - Briceño, Hansen, and Walker-Loud [PRD 91 (2015) 3 034501](https://doi.org/10.1103/PhysRevD.91.034501)\n",
    " - Hansen and Sharpe [PRD 90 (2014) 11 116003](https://doi.org/10.1103/PhysRevD.90.116003), [PRD 92 (2015) 11 114509](https://doi.org/10.1103/PhysRevD.92.114509), [PRD 93 (2016) 014506](https://doi.org/10.1103/PhysRevD.93.014506), [PRD 93 (2016) 9 096006](https://doi.org/10.1103/PhysRevD.93.096006) and [erratum](https://doi.org/10.1103/PhysRevD.96.039901), [PRD 95 (2017) 3 034501](https://doi.org/10.1103/PhysRevD.95.034501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morever, there has been enormous success in *actually applying Lüscher's technique to learn about QCD*!  \n",
    "\n",
    "**Here is a substantially incomplete list**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesonic sector is by far the most sophisticated, and it's essentially impossible to cover the entire literature.\n",
    "\n",
    "For recent progress, and a nearly-comprehensive-to-that-point review see\n",
    "\n",
    " - Briceño, Dudek, and Young [Rev.Mod.Phys. 90 (2018) 025001](https://doi.org/10.1103/RevModPhys.90.025001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once there are baryons, measuring correlators is much more painful and progress lags in comparison.\n",
    "\n",
    "In the single-baryon sector, see\n",
    "\n",
    " - Lang and Verduci [PRD 87 (2013) 054502](https://doi.org/10.1103/PhysRevD.87.054502)\n",
    " - Kiratidis, Kamleh, Leinweber, Liu, Stokes, and Thomas [PRD 95 (2017) 074507](https://doi.org/10.1103/PhysRevD.95.074507)\n",
    " - Lang, Leskovec, Padmanath, and Prelovsek [PRD 95 (2017) 014510](https://doi.org/10.1103/PhysRevD.95.014510), [EPJ Web Conf. 175 (2018) 05004](https://doi.org/10.1051/epjconf/201817505004)\n",
    "\n",
    "For two nucleon scattering, see\n",
    "\n",
    " - PACS-CS [PRD 84 (2011) 054506](https://doi.org/10.1103/PhysRevD.84.054506)\n",
    " - Yamazaki et al. [PRD 86 (2012) 074514](https://doi.org/10.1103/PhysRevD.86.074514)\n",
    " - NPLQCD [PRD 87 (2013) 3 034506](https://doi.org/10.1103/PhysRevD.87.034506)\n",
    " - Yamazaki et al. [PRD 92 (2015) 1 014501](https://doi.org/10.1103/PhysRevD.92.014501)\n",
    " - NPLQCD [PRD 92 (2015) 11 114512](https://doi.org/10.1103/PhysRevD.92.114512)\n",
    " - CalLat [PLB 765 (2017) 285-292](https://doi.org/10.1016/j.physletb.2016.12.024)\n",
    " - NPLQCD [PRD 96 (2017) 11 114510](https://doi.org/10.1103/PhysRevD.96.114510)\n",
    " \n",
    "and for few-body matrix elements,\n",
    "\n",
    " - NPLQCD PRL 119 (2017) 6 [062002](https://doi.org/10.1103/PhysRevLett.119.062002) and [062003](https://doi.org/10.1103/PhysRevLett.119.062003)\n",
    " - NPLQCD [PRD 96 (2017) 5 054505](https://doi.org/10.1103/PhysRevD.96.054505)\n",
    " - NPLQCD [PRL 120 (2018) 15 152002](https://doi.org/10.1103/PhysRevLett.120.152002)\n",
    "\n",
    "while for studies of the H dibaryon, see\n",
    "\n",
    " - NPLQCD [Mod. Phys. Lett A26 (2011) 2587-2595](https://doi.org/10.1142/S0217732311036978)\n",
    " - NPLQCD [PRL 106 (2011) 162002](https://doi.org/10.1103/PhysRevLett.106.162001)\n",
    " - Francis et al. [arXiv:1805.03966](http://arxiv.org/abs/arXiv:1805.03966)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will work through a simple problem in the same spirit: two interacting nonrelativistic quantum-mechanical particles in one spatial dimension.  \n",
    "\n",
    "The approach will be as follows:\n",
    "1. Set up the Hamiltonian of interest and review how putting it in a finite volume produces a quantization conditon.  We'll consider a ring of radius $L$.\n",
    "2. Briefly review the S and T matrices.\n",
    "3. Examine the infinite- and finite-volume cases.  Derive the quantization condition.  The quantization condition is the map from the finite-volume energies to scattering phase shift.\n",
    "\n",
    "At that point, we will understand where Lüscher's formula comes from.  Then, we will apply it,\n",
    "\n",
    "3. Discretize the finite-volume problem and extract its spectrum for a variety of radii.\n",
    "4. Using the quantization condition, translate the energies found into phase shifts and compare with what we found in the infinite-volume case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lattice QCD we do not have access to the nuclear Hamiltonian.  However, we can nevertheless determine its spectrum and use the quantization condition to translate those results into phase shifts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Quantum Mechanics Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two distinguishable quantum mechanical particles that move in one infinite spatial dimension.  Let their interaction potential $V$ depend only on their separation.  Then, their Hamiltonian is given by\n",
    "\n",
    "$$ \\mathcal{H} = \\frac{p_1^2}{2 m_1} + \\frac{p_2^2}{2 m_2} + V(x_1-x_2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can switch to center-of-mass and relative coordinates.  Let\n",
    "\n",
    "\\begin{align}\n",
    "    M &= m_1 + m_2                      &  \\mu &= \\frac{m_1 m_2}{M} \\\\\n",
    "    X &= \\frac{m_1 x_1 + m_2 x_2}{M}    &    x &= x_1 - x_2          \\\\\n",
    "    K &= p_1+p_2                        &    k &= \\frac{m_2 p_1 - m_1 p_2}{M}                \\\\\n",
    "    U &= Q / M                          &    u &= q/\\mu\n",
    "\\end{align}\n",
    "\n",
    "where the capital letters are center-of-mass variables, lower case letters are relative-coordinate variables, $M$ is mass, $X$ is position, $K$ is momentum, and $U$ is velocity.\n",
    "\n",
    "Then it is easy to check the canonical commutation relations $[X,K]=[x,k]=i$ hold, and that $[X,k]=[x,K]=0$, so that we have completely decoupled the center-of-mass and relative motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check that $[X,K]=[x,k]=i$ and that $[X,k]=[x,K]=0$, assuming the canonical commutation relations $[x_i,p_j]=i \\delta_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check that the Hamiltonian may be rewritten in the new variables,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{H} = \\frac{K^2}{2 M} + \\frac{k^2}{2 \\mu} + V(x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these coordinates, it's clear that, as long as $V$ is even, there is a parity symmetry,\n",
    "\n",
    "\\begin{align}\n",
    "    x &\\rightarrow -x      &\n",
    "    k &\\rightarrow -k\n",
    "\\end{align}\n",
    "\n",
    "because $[H, \\mathcal{P}]=[V(x), \\mathcal{P}]=0$ where $\\mathcal{P}$ is the operator implementing the above transformation.\n",
    "\n",
    "Moreover, the center of mass is completely free.  So, the physical infinite-volume observables can only be a function of the relative momentum $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have completely decoupled the center-of-mass degrees of freedom from the relative motion, we know the eigenfunctions can be expressed as products,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Psi(X,x) = e^{i K X} \\psi_K(x)\n",
    "\\end{equation}\n",
    "\n",
    "up to normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodicity Gives Quantization Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, it's a familiar idea that putting a system in a finite volume yields quantization conditions.\n",
    "\n",
    "The periodicity condition is for the individual particles–––not the center-of-mass and relative degrees of freedom.  Let's translate one to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the same Hamiltonian where each particle is now on the same one-dimensional ring of radius $L$.  That is, we identify $-\\pi L$ with $\\pi L$.  The periodicity is easily expressed in terms of the variables $x_1$ and $x_2$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Psi(x_1 + 2 \\pi L n_1, x_2 + 2 \\pi L n_2) = \\Psi(x_1, x_2)\n",
    "\\end{equation}\n",
    "\n",
    "where $n_1$ and $n_2$ are any integers.  They tell us how many times the particle orbits the ring under our transformation.\n",
    "\n",
    "We need to change this restriction on the wavefunction into a quantization condition that relates the energies and phase shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAUTION:\n",
    "\n",
    "In LQCD literature one typically finds the circumference $2\\pi L$ called $L$.  That's natural, since the circumference is just the number of lattice sites times the lattice spacing.  However, it means you have to carry around lots of factors of $2\\pi$ everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here we could include *twisted boundary conditions*, where each particle picks up a phase over the course of an orbit.  Twisted boundary conditions are sometimes applied to the quarks in lattice QCD–––the hadrons' twists are then determined.  For simplicity, we just mention this in passing and proceed in the specialized, untwisted case.\n",
    "\n",
    "Physically motivated, twisted boundary conditions are what you get when you thread a magnetic field through the ring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we make the transformations $x_i \\rightarrow x_i + 2\\pi L n_i$ the collective coordinates change according to\n",
    "\n",
    "\\begin{align}\n",
    "    X &\\rightarrow X+\\Delta X &&= X + 2\\pi L \\frac{m_1 n_1+m_2 n_2}{M} \\\\\n",
    "    x &\\rightarrow x+\\delta x &&= x + 2\\pi L (n_1-n_2)\n",
    "\\end{align}\n",
    "\n",
    "Rewriting the periodicity condition in collective coordinates yields\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Psi(X+\\Delta X, x+\\delta x) = \\Psi(X,x)\n",
    "\\end{equation}\n",
    "\n",
    "and using the factorized wavefunction, this becomes\n",
    "\n",
    "\\begin{align}\n",
    "    e^{i K X + i K \\Delta X}\\psi_K(x+\\delta x) &= e^{i K X}\\psi_K(x) \\\\\n",
    "    e^{i 2\\pi L K \\frac{m_1 n_1+m_2n_2}{M}} \\psi_K(x+2\\pi L(n_1-n_2)) &= \\psi_K(x) \\\\\n",
    "    e^{2\\pi i L K n_2 + 2\\pi i K L \\frac{m_1}{M}(n_1-n_2)} \\psi_K(x+2\\pi L(n_1-n_2)) &= \\psi_K(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this should hold for any $n_1$ and $n_2$, set them both equal to 1 to find\n",
    "\n",
    "\\begin{equation}\n",
    "    e^{2\\pi i L K} = 1\n",
    "\\end{equation}\n",
    "\n",
    "so that the center-of-mass momentum is quantized,\n",
    "\n",
    "\\begin{equation}\n",
    "    K = \\frac{N}{L}\n",
    "\\end{equation}\n",
    "\n",
    "for integers $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can simplify further.  Let $\\nu = n_1 - n_2$, an integer.  Then we find\n",
    "\n",
    "\\begin{equation}\n",
    "    e^{2\\pi i N \\nu \\frac{m_1}{M}} \\psi_N(x+2\\pi L \\nu) = \\psi_N(x)\n",
    "\\end{equation}\n",
    "\n",
    "which says that the relative wavefunction experiences a center-of-mass-momentum-dependent twist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "How did the quantization condition pick out $m_1$ over $m_2$?  Is something broken?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For simplicity, let's focus on the case where $N=0$, where the center of mass is at rest.**\n",
    "\n",
    "Then, we have a simple periodicity condition for the relative wavefunction,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\psi(x+2\\pi L \\nu) = \\psi(x)\n",
    "\\end{equation}\n",
    "\n",
    "where we have dropped the center-of-mass label to clean up notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the noninteracting case, we know that this periodicity equation is solved by sines and cosines–––eigenfunctions whose energies are $n^2/2\\mu L^2$.  However, with nonzero interaction potential those wavefunctions will deform and their energies will shift.  How those shifts are related to the scattering data is what we're after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "If we had included twisted boundary conditions, what would have changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The S Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the scattering of two particles incident on one another in one dimension.  As the experimenter, we have the ability to control the momenta of the individual particles at the beginning of our scattering experiment.  That lets us set the initial $p_1$ and $p_2$ and thus the initial $K$ and $k$ arbitrarily.\n",
    "\n",
    "After the particles interact, their momenta may be changed.  How this exactly happens we don't get to investigate–––we just have access to the asymptotic states.  What we do know, of course, is that center-of-mass momentum and energy are separately conserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed above, we can trade a two-particle system for a one-particle system with a stationary potential (as long as we remember what we chose for $K$–––but we'll focus on the $K=0$ sector).\n",
    "\n",
    "**We now adopt one-particle language for simplicity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The momenta after scattering is entirely fixed by kinematics, and is especially simple in 1 dimension.  \n",
    "\n",
    "Conservation of energy and momentum imply that the only allowed final relative momenta are $\\pm q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can separately discuss cases when the particle is to the left or right of the potential,\n",
    "\n",
    "\\begin{align}\n",
    "    x &> 0 && \\text{\"on the right\"} \\\\\n",
    "    x &< 0 && \\text{\"on the left\"}\n",
    "\\end{align}\n",
    "\n",
    "We can also identify cases where the particle is incident on on the potential or if it's heading away from the potential.  $q$ tells us which direction the particle is moving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have four kinds of states, two incoming states and two outgoing states:\n",
    "\n",
    "\\begin{align}\n",
    "        \\langle x |k; \\text{incoming from the left} \\rangle &\\sim e^{+i k x}\\theta(-x)\n",
    "    &   \\langle x |k; \\text{outgoing to the right}  \\rangle &\\sim e^{+i k x}\\theta(+x) \\\\\n",
    "        \\langle x |k; \\text{outgoing to the left}   \\rangle &\\sim e^{-i k x}\\theta(-x)\n",
    "    &   \\langle x |k; \\text{incoming from the right}\\rangle &\\sim e^{-i k x}\\theta(+x)\n",
    "\\end{align}\n",
    "\n",
    "where the Heaviside-$\\theta$ function tells us where the particle is in relation to the potential and the sign of $k$ tells us where it's heading.  We understand that the $\\theta$-functions are really telling us in which asymptotic region we're supposed to be looking in–––we don't really have access to the wavefunction inside the range of the potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $S$-matrix is the map that takes some incoming states and produces some outgoing states.  If our initial state is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left|\\Psi_i\\right\\rangle = \\alpha \\left|k; \\text{incoming from the left}\\right\\rangle \n",
    "                              + \\beta  \\left|k; \\text{incoming from the right}\\right\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "and the final state by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left|\\Psi_f\\right\\rangle = a      \\left|k; \\text{outgoing to the right}\\right\\rangle\n",
    "                              + b      \\left|k; \\text{outgoing to the left}\\right\\rangle.\n",
    "\\end{equation}\n",
    "\n",
    "Then the $S$-matrix relates the coefficients,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left(\\begin{matrix} a \\\\ b\\end{matrix}\\right) \n",
    "    = S\n",
    "    \\left(\\begin{matrix} \\alpha \\\\ \\beta \\end{matrix}\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now move to interactions with good parity.  We can symmetrize to states of even ($+1$) and odd ($-1$) parity,\n",
    "\n",
    "\\begin{align}\n",
    "    \\langle X, x \\mid k; \\text{incoming, parity }P \\rangle &\\sim \\left(e^{+i k x} \\theta(-x) + P e^{-i k x} \\theta(+x) \\right)/\\sqrt{2} \\\\\n",
    "    \\langle X, x \\mid k; \\text{outgoing, parity }P \\rangle &\\sim \\left(e^{+i k x} \\theta(+x) + P e^{-i k x} \\theta(-x) \\right)/\\sqrt{2}\n",
    "\\end{align}\n",
    "\n",
    "and rewrite the asymptotic states\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left|\\Psi_i, k; \\text{parity }P\\right\\rangle \n",
    "    = \\alpha_\\pm \\left|k; \\text{incoming, parity }P\\right\\rangle \n",
    "\\end{equation}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left|\\Psi_f, k; \\text{parity }P\\right\\rangle \n",
    "    = a_\\pm      \\left|k; \\text{outgoing, parity }P\\right\\rangle \n",
    "\\end{equation}\n",
    "\n",
    "Because of the symmetry of the Hamiltonian, we know the $S$ matrix doesn't mix these different parities.  So, we have diagonalized $S$-matrix,\n",
    "\n",
    "\\begin{align}\n",
    "    a_+ &= S_+ \\alpha_+\n",
    "    &\n",
    "    a_- &= S_- \\alpha_-\n",
    "\\end{align}\n",
    "\n",
    "In three spatial dimensions, the spiritually equivalent rewriting is in the basis of good angular momentum.\n",
    "\n",
    "Since $S$ is unitary and the different channels don't talk to one another, each channel has its own independent scattering phase shift $\\delta(k)$ that depends on the scattering momentum and determines the $S$ matrix  $S_\\pm = \\exp\\left(2 i \\delta_\\pm(k)\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization Condition for the Relative Wavefunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a time-independent state––which is another way to say a Hamiltonian eigenstate––where what's coming out of the scattering region reaches the periodic boundary and becomes the incoming wave, the relative wavefunction should, asymptotically, be some superposition of the incoming and outgoing states above.\n",
    "\n",
    "Let $\\psi(x) = \\alpha\\ \\psi_\\text{incoming}(x) + a\\ \\psi_\\text{outgoing}(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the $N=0$ sector, the periodicity condition reads\n",
    "\n",
    "\\begin{equation}\n",
    "    \\psi(x+2\\pi L \\nu) = \\psi(x)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\psi$ is the relative wavefunction.  Let's let $\\nu=1$ and set $x=-\\pi L$.  If $L$ is bigger than the range of the interaction, this is in the region where the wavefunctions look asymptotically like plane waves.\n",
    "\n",
    "\\begin{align}\n",
    "    \\psi(-\\pi L) &= \\psi(+\\pi L)\n",
    "    \\\\\n",
    "    \\alpha e^{+i k (-\\pi L)} + a P e^{-i k (-\\pi L)} &= \\alpha P e^{-i k (+\\pi L)} + a e^{+i k (+\\pi L)}\n",
    "\\end{align}\n",
    "\n",
    "Massaging, one finds\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{a}{\\alpha} = e^{-2\\pi i k L}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the two wavefunction components are related by the $S$ matrix then $a/\\alpha = e^{2i\\delta(k)}$ and\n",
    "\n",
    "\\begin{equation}\n",
    "    e^{2 i \\delta(k) + 2\\pi i k L} = 1\n",
    "\\end{equation}\n",
    "\n",
    "That's it.  That's Lüscher's formula for 1D quantum mechanics!\n",
    "\n",
    "Note that it contains no information about the interaction potential at all whatsoever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one dimension, to make the expression schematically match other dimensions, it is often written\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{1}{k} \\cot\\delta(k) = \\frac{L}{\\pi} S_1\\left( 2 \\mu E L^2 \\right)\n",
    "    \\qquad\n",
    "    S_1(x) = -\\pi \\frac{\\cot \\pi \\sqrt{x}}{\\sqrt{x}}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Show that this more complicated-looking expression is the same as the simple $e^{2i\\delta(k) + 2\\pi i k L}=1$, when the on-shell condition $k^2 = 2\\mu E$ is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "I slighted you a bit.  When $P=+1$ the periodicity condition actually reduces to 0=0.  When the wavefunction is parity-even, of COURSE the wavefunction at $-\\pi L$ is the same as the wavefunction at $+\\pi L$.  Continuity across the boundary is guaranteed.  However, it's not guaranteed to be smooth.\n",
    "\n",
    "Convince yourself that when $P=+1$, matching the derivative of the relative wavefunction reproduces the same quantization condition, and importantly, that matching the derivative doesn't overconstrain the $P=-1$ case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1.  What spatial symmetry/symmetries do the one-dimensional periodic boundary conditions have?  What spatial symmetry/symmetries does the Hamiltonian have?\n",
    "\n",
    "2.  Generalize the implementation of periodic boundary conditions to three spatial dimensions in terms of matching arguments of wavefunctions.  What kind of functions solve them?\n",
    "\n",
    "3.  Do the solutions to the periodic boundary conditions look like eigenfunctions of the Hamiltonian?  What spatial symmetries do the three-dimensional conditions have?  Do these match the symmetries you might expect from a physically reasonable Hamiltonian, or more specifically, the symmetries of QCD?  Is one set of symmetries smaller than the other?  Does one contain the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed, the $S$-matrix relates asymptotic incoming states to asymptotic outgoing states.  This relation is fundamentally different from the relation given by the periodic boundary conditions.  Recall our earlier discussion: the $S$-matrix is the map that takes some incoming states and produces some outgoing states.  The boundary conditions select which, of all asymptotic states, fit just so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I recommend skipping the T-matrix discussion.  Head to [the recap section](#recap) below.**\n",
    "\n",
    "I include the T-matrix discussion because it is a more modern and generic way to arrive at the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside: A More Grown-Up Derivation via the T Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From general scattering theory, we know $S=1+iT$, and that $T$ admits a partial wave expansion.  As a reminder, in three spatial dimensions,\n",
    "\n",
    "\\begin{align}\n",
    "    S_l(k) &= 1 + 2 i k f_l(k) & \\text{or}&& f_l &= \\frac{1}{k \\cot \\delta_l - i k}\n",
    "\\end{align}\n",
    "\n",
    "The analogous result in 1 spatial dimension is\n",
    "\n",
    "\\begin{equation}\n",
    "    T = \\frac{k}{\\mu} \\frac{1}{\\cot \\delta(k) - i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $T$ matrix may be calculated diagrammatically.  In our theory we have a single propagating particle that now and then hits the potential.  Diagrammatically, we have\n",
    "\n",
    "<img src=\"diagram/t.jpg\">\n",
    "\n",
    "where the solid line indicates free propagation asymptotically far from the potential and intersection with the dashed, terminated line indicates the external potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rewriting of everybody's favorite formulation of the Schrödinger equation, the Lippmann-Schwinger equation, written as a Born series,\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat{T} &= \\hat{V} + \\hat{V} \\hat{G}_0 \\hat{T} \\\\\n",
    "    \\hat{T} &= \\hat{V} + \\hat{V} \\hat{G}_0 \\hat{V} + \\hat{V} \\hat{G}_0 \\hat{V} \\hat{G}_0 \\hat{V} + \\cdots\n",
    "\\end{align}\n",
    "\n",
    "where $G_0 = (E - H_0)^{-1}$ is the free Green's function,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle k_f | G_0 | k_i \\rangle = \\frac{1}{E-\\frac{k_i^2}{2\\mu}} \\delta(k_f-k_i).\n",
    "\\end{equation}\n",
    "\n",
    "The Lippmann-Schwinger equation is, in general, a horrible integral equation.  \n",
    "\n",
    "(The diagrammatic expansion of $T$ also looks a lot like familiar Lagrangian perturbation theory, the main difference being where factors of $i$ show up.  Don't worry–––everything shakes out correctly no matter which approach you adopt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases of physical interest, however, we can greatly simplify.  Suppose the potential is *factorizable*,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle k_f | V | k_i \\rangle = c f(k_f) g(k_i).\n",
    "\\end{equation}\n",
    "\n",
    "Then, we have a dramatic simplification and find that $T$ is given by a geometric series,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle k_f | T | k_i \\rangle = \\frac{V(k_f, k_i)}{1-\\int \\frac{\\mathrm{d}p}{2\\pi} V(p,p) G_0(p,p)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun But Unimportant Diversion For Later Entertainment\n",
    "\n",
    "Check that the above claim is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Are any familiar physically interesting potentials factorizable?\n",
    "\n",
    "### Question:\n",
    "\n",
    "Are any familiar physically interesting potentials NOT factorizable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to evaluate the $T$ matrix in both the infinite volume and finite volume.  By matching them together we can see how the restriction to the finite volume quantizes the physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In quantum field theories you can produce particles if there's enough energy in your system.  In that case we say that there's an inelastic threshold, and an analysis as simple as the one above doesn't go through.  However, you can build in inelastic physics and handle things with a coupled-channel method.  It adds a lot of complicated detail and computational difficulty, and isn't of particular interest here.  Suffice it to say that we're interested in low-energy phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as that's true, we expect the potential to admit an low-momentum expansion.  This can be done in a model-independent way using Effective Field Theory (EFT) methods.  We can, for example, say that the potential is given by \n",
    "\n",
    "\\begin{equation}\n",
    "V(k) = \\sum C_{2n} k^{2n},\n",
    "\\end{equation}\n",
    "\n",
    "which, in position space, is a gradient expansion of contact operators, and where the coefficients $C_{2n}$ may be scale dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the integral\n",
    "\n",
    "\\begin{equation}\n",
    "    \\int \\frac{\\mathrm{d}p}{2\\pi} \\sum_n C_{n2}p^{2n} \\frac{1}{E- \\frac{p^2}{2\\mu} + i\\epsilon}\n",
    "\\end{equation}\n",
    "\n",
    "term-by-term.  Using dimensional regularization, I find that the $n^{th}$ term is\n",
    "\n",
    "\\begin{equation}\n",
    "    -i \\mu C_{2n} (2\\mu E)^{n-\\frac{1}{2}}\n",
    "\\end{equation}\n",
    "\n",
    "On shell, we can use $2\\mu E = k^2$ to simplify dramatically and find\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\frac{V(k)}{1- i \\frac{\\mu V(k)}{\\sqrt{2\\mu E}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the corresponding finite-volume sums is a job for Mathematica.  It's actually quite a subtle business to get this right, as the sums diverge and I don't know a \"dim reg\" for sums.  We have to match the divergences of the infinite volume and the finite volume, adjusting the coefficients $C$ so that physical observables remain cutoff independent.  See, for example, [Beane, Bedaque, Parreno, and Savage, PLB 585 (2004) 106-114](https://www.sciencedirect.com/science/article/pii/S0370269304002618?via%3Dihub), where things are done with a hard cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one dimension, the contact interaction is completely convergent and you don't have to worry.  Let's evaluate the integral so we see what we're ultimately trying to accomplish.\n",
    "\n",
    "\\begin{align}\n",
    "    \\int\\frac{\\mathrm{d}p}{2\\pi} V(p,p) G_0(p,p) &= \n",
    "    \\int \\frac{\\mathrm{d}p}{2\\pi} C_0 \\frac{1}{E-\\frac{p^2}{2\\mu}} \n",
    "    \\\\\n",
    "    &\\sim \\frac{1}{2\\pi L} \\sum_{n} C_0 \\frac{1}{E-\\frac{p_n^2}{2\\mu}}\n",
    "    \\\\\n",
    "    &= -\\frac{\\mu C_0 }{\\pi L} \\sum_n \\frac{1}{\\frac{n^2}{L^2} - 2\\mu E}\n",
    "    \\\\\n",
    "    &= -\\frac{\\mu C_0 L}{\\pi} \\sum_n \\frac{1}{n^2 - 2 \\mu E L^2}\n",
    "    \\\\\n",
    "    &= -\\frac{\\mu C_0 L}{\\pi}\\ S_1\\left(2\\mu E L^2\\right)\n",
    "\\end{align}\n",
    "\n",
    "where we have defined\n",
    "\n",
    "\\begin{equation}\n",
    "    S_1(x) = - \\frac{\\pi \\cot \\pi \\sqrt{x}}{\\sqrt{x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Lüscher's Formula\n",
    "\n",
    "Since we have focused on the sum for the contact interaction, let $V(k) = C_0 = g$.  The infinite-volume on-shell $T$-matrix is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    T_\\infty = \\frac{g}{1- \\frac{i g \\mu}{\\sqrt{2\\mu E}}}\n",
    "\\end{equation}\n",
    "\n",
    "which we argued we know is generically\n",
    "\n",
    "\\begin{equation}\n",
    "    T = \\frac{k}{\\mu} \\frac{1}{\\cot \\delta(k) - i}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What is the energy of the bound state in the case $g<0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Massage those two expressions for $T$ to recover an expression for the infinite-volume scattering phase shift, or easier, $\\cot\\delta$, for the contact interaction.  This is the exact answer that we hope to recover by doing some finite-volume calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two-nucleon QCD case we don't know $g$––it's some emergent property of QCD that shows up in the EFT you're using to describe the hadronic physics.  But we can use the result you just found and eliminate $g$ from the finite-volume $T$ matrix.  It's clear from our derivation from matching boundary conditions that this goes through generically, although we focused on the contact interaction here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Massage \n",
    "\n",
    "\\begin{equation}\n",
    "    T_L = \\frac{g}{1 + \\frac{\\mu g L}{\\pi} S_1\\left(2\\mu EL^2\\right)}\n",
    "\\end{equation}\n",
    "\n",
    "and eliminate $g$ in favor of $\\cot\\delta$.  Where are the poles of $T_L$?  Note that this is independent of $g$!  *This is Lüscher's formula for this simple problem*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap before Numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can follow this story, you understand conceptually the whole thing.  The complication of what you see in the literature is simply handling the difficulties of three dimensions, incorporating twisted boundary conditions, having multiple open channels, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one spatial dimension we have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{1}{k} \\cot\\delta(k) = \\frac{L}{\\pi} S_1\\left( 2 \\mu E L^2 \\right)\n",
    "    \\qquad\n",
    "    S_1(x) = -\\pi \\frac{\\cot \\pi \\sqrt{x}}{\\sqrt{x}},\n",
    "\\end{equation}\n",
    "\n",
    "where the energy $E$ defines the scattering momentum through $E = k^2/2\\mu$.  We arrived at this relation simply by demanding continuity and smoothness of the wavefunction across the periodic boundary conditions, without any concern for the microscopic physics that determines $S$ (or $\\delta$).  Indeed, this formula doesn't have anything about the details of the interaction in it––only the asymptotic observable the interaction generates: the phase shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lüscher formula allows us to translate the finite-volume spectrum into scattering information.  The procedure is as follows:\n",
    "\n",
    "0.  Fix the infinite-volume parameters (the masses and their interaction potential).\n",
    "1.  Fix a box size $L$.\n",
    "2.  Determine the energy spectrum with a definitive center of mass momentum given by $N$.\n",
    "3.  Use the energy level to extract $k$.\n",
    "4.  Use the relation above to compute the phase shift $\\delta$ at that relative momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll use finite-volume spectra and actually carry through this program.  However, we'll extract the finite-volume spectra from direct Hamiltonian diagonalization rather than a stochastic lattice calculation.  The above formula doesn't care how you get your hands on energy levels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the spectrum of the finite-volume Hamiltonian by direct diagonalization.  In contrast, the finite-volume spectrum in QCD is extracted by stochastically measuring correlation functions.  The Lüscher formalism doesn't care how you obtained the finite-volume spectrum–––it simply tells you how to take that spectrum and extract infinite-volume phase shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll slowly build up the Hamiltonian $\\mathcal{H}$.  We'll think of the wavefunction $\\psi$ as the vectors on which operators work.  Each entry in the vector will represent the wavefunction at a different spatial point.  We'll solve the time-independent Schrödinger equation\n",
    "\n",
    "\\begin{equation}\n",
    "H \\left|\\psi_n\\right\\rangle = E_n \\left|\\psi_n\\right\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "We just need simple linear algebra and plotting utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want large, visible figures:\n",
    "plt.rcParams['figure.figsize'] = (12,9)\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 'large'\n",
    "\n",
    "# Frustratingly, these magic incantations only work if \n",
    "# not in the same cell as the import statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve a Hermitian matrix using built-in `numpy` tools.  The linear algebra eigensolver annoyingly returns the eigenvectors in columns, rather than in rows.  That's great if you're interested in matrix-vector multiplication, but it makes it annoying to `zip` over eigenvalue-eigenvector pairs, which we'll want to do.  So that we don't make a mistake, here's a little solver that makes them zippable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(hermitian_matrix):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(hermitian_matrix)\n",
    "    return eigenvalues, eigenvectors.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to discretize a ring with radius $L$.  One might want all sorts of meshes.  Here we will just consider a mesh with uniform spacing.  Let us conventionally discretize the range $L * [-\\pi,\\pi)$ with $N$ evenly-spaced points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_discretization(N, L):\n",
    "    return np.pi * L * np.arange(-1,1,2/N), 2 * np.pi * L / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might want to specify the lattice spacing $a$ and the number of sites instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_and_count(a,N):\n",
    "    return a*np.arange(-N//2, (N+1)//2, 1), a*N/(2*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize progressively finer uniform discretizations for a few radii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_refinement = plt.figure()\n",
    "axes = mesh_refinement.add_subplot(1,1,1)\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "Ls = [1,2]\n",
    "Ns = 2**np.arange(2,6)\n",
    "for L in Ls:\n",
    "    for N in Ns:\n",
    "        ring, spacing = uniform_discretization(N,L)\n",
    "        axes.plot(L*np.cos(ring/L), L*np.sin(ring/L), label=\"N=%i L=%i\"%(N,L))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, at larger radii we should maybe expect worse discretization effects for a fixed $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note what happens if we make $N$ odd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_n = plt.figure()\n",
    "axes = odd_n.add_subplot(1,1,1)\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "\n",
    "L=1\n",
    "for N in 2*np.arange(3,10,2)+1:\n",
    "    ring, spacing = uniform_discretization(N,L)\n",
    "    axes.plot(L*np.cos(ring/L), L*np.sin(ring/L), label=\"N=%i L=%i\"%(N,L))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We *always* miss $x=0$.  So if we're going to put some sort of regularized Dirac delta function potential down, we'd better be careful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting an operator's spectrum and eigenfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(lattice, eigenvalues, eigenvectors, modes=None):\n",
    "    \n",
    "    vals = eigenvalues\n",
    "    vecs = eigenvectors\n",
    "    if modes is not None:\n",
    "        vals = vals[0:modes]\n",
    "        vecs = vecs[0:modes]\n",
    "\n",
    "    for v,f in zip(vals,vecs):\n",
    "        wavefunction, = plt.plot(lattice,abs(v)*(np.sign(v)+f), linestyle='-')\n",
    "        plt.hlines(v,min(lattice),max(lattice), color = wavefunction.get_color(), linestyle = \":\", label=\"E=%f\"%v)\n",
    "    \n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$\\psi_n(x)+E_n$')\n",
    "    plt.legend(bbox_to_anchor=(1.04,1))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only considering uniform meshes we can easily write the second-derivative operator as a tri-diagonal matrix, using the finite-difference approximation\n",
    "\\begin{equation}\n",
    "  f''(x_i) = \\frac{f(x_{i+1})-2 f(x_i) + f(x_{i-1})}{(\\Delta x)^2} + \\mathcal{O}(\\Delta x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinetic energy operator for a particle with mass $m$ is given by\n",
    "\\begin{equation}\n",
    "    T_m = - \\frac{1}{2 m} \\partial^2\n",
    "\\end{equation}\n",
    "We need to specify both a mass and a discretization.\n",
    "\n",
    "The function `T` is of type `mass --> discretization --> operator`.  It currently assumes a uniform discretization and periodic boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(mass):\n",
    "    minus_one_over_twice_mass = -1./(2*mass)\n",
    "\n",
    "    def curried(discretization):\n",
    "        spatial_dimension=len(discretization)\n",
    "        operator = np.zeros([spatial_dimension,spatial_dimension])\n",
    "\n",
    "\n",
    "        # The below assumes a uniform discretization!\n",
    "        dx = discretization[1] - discretization[0]\n",
    "        one_over_dx_squared = 1/(dx**2)\n",
    "\n",
    "        factor = one_over_dx_squared * minus_one_over_twice_mass\n",
    "\n",
    "        for i in range(spatial_dimension):\n",
    "            operator[i,i] = -2. * factor\n",
    "        for i in range(1,spatial_dimension):\n",
    "            operator[i,i-1] = +1. * factor\n",
    "        for i in range(spatial_dimension-1):\n",
    "            operator[i,i+1] = +1. * factor\n",
    "\n",
    "        # Periodic boundary conditions:\n",
    "        operator[0,-1] = +1. * factor\n",
    "        operator[-1,0] = +1. * factor\n",
    "\n",
    "        return operator\n",
    "    return curried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the stencil that the kinetic energy operator makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=1\n",
    "N=32\n",
    "\n",
    "lattice, spacing = uniform_discretization(N,L)\n",
    "mass = 1\n",
    "\n",
    "KE = T(mass)(lattice)\n",
    "\n",
    "kinetic_operator = plt.figure()\n",
    "axes = kinetic_operator.add_subplot(1,1,1)\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "axes.imshow(KE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can get the spectrum of the free particle on a ring.\n",
    "\n",
    "We know the exact solution has wavefunctions like $\\exp(i n x / L)$ and thus momenta that take values $n/L$.  The finite difference is\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{1 - \\cos(a p)}{a^2}\n",
    "\\end{equation}\n",
    "\n",
    "and we can check if our operator gives that dispersion relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = np.arange(-N/2,N/2)/(L)\n",
    "energy = (1-np.cos(spacing*momentum))/spacing**2\n",
    "plt.plot(momentum,energy)\n",
    "\n",
    "free_particle = solve(KE)\n",
    "\n",
    "# Positive momentum modes:\n",
    "plt.plot(free_particle[0][::2],\"o\")\n",
    "\n",
    "# Negative momentum modes:\n",
    "plt.plot(np.arange(-N/2,0),free_particle[0][-1::-2],\"o\")\n",
    "\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('$KE_n$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can plot the spectrum with the wavefunctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_spectrum(lattice, free_particle[0], free_particle[1], 11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each nonzero energy level we see two orthogonal eigenfunctions, which we can combine to the parity even and odd eigenfunctions.\n",
    "\n",
    "We can see that the wavefunctions are losing their smoothness, pretty low in the spectrum, even for $N_x=32$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential energy is easier than the kinetic, because it is entirely local: doesn't contain derivatives.  It is therefore put on the lattice very simply: we just evaluate the potential on each site and stick that on the diagonal of the operator.\n",
    "\n",
    "The function `V` is of type `potential --> discretization --> operator`.  Later I will give an example of how to construct the `potential` argument, which is a function from `position --> energy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(potential):\n",
    "    def curried(discretization):\n",
    "        spatial_dimension=len(discretization)\n",
    "        operator = np.zeros([spatial_dimension,spatial_dimension])\n",
    "\n",
    "        for i in range(spatial_dimension):\n",
    "            operator[i,i] = potential(discretization[i])\n",
    "\n",
    "        return operator\n",
    "    return curried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's regulate the dirac delta function as a square potential of width $\\epsilon$ and height $1/\\epsilon$ centered on zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirac_delta(g, epsilon):\n",
    "    def curried(x):\n",
    "        if -epsilon/2 <= x <= +epsilon/2:\n",
    "            return g / epsilon \n",
    "        else:\n",
    "            return 0\n",
    "    return curried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hamiltonian $\\mathcal{H}$ is simply the sum of the kinetic and potential energies.\n",
    "\n",
    "It is of type `(T, V) --> discretization --> operator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian(kinetic, potential):\n",
    "    def curried(discretization):\n",
    "        return kinetic(discretization) + potential(discretization)\n",
    "    return curried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idiot Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check let's look at the spectrum for a particular example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = -1.2\n",
    "mass = 10.32\n",
    "spacing = 0.01\n",
    "\n",
    "predicted_binding_energy = -g**2 * mass / 2;\n",
    "\n",
    "# Let's programmatically make sure our lattice fits the bound state comfortably:\n",
    "wavefunction_decay_scale = 1/np.sqrt(2*np.abs(predicted_binding_energy))\n",
    "circumference = 3*wavefunction_decay_scale\n",
    "sites = np.floor(circumference/spacing)\n",
    "\n",
    "# The spacing isn't exactly what we asked for if it didn't evenly divide the circumference.\n",
    "lattice, spacing=uniform_discretization(sites, circumference/(2*np.pi))\n",
    "\n",
    "# Set up...\n",
    "H=hamiltonian(T(mass), V(dirac_delta(g, spacing)))\n",
    "# ... and solve!\n",
    "eigenvalues, eigenfunctions = solve(H(lattice))\n",
    "\n",
    "interacting_spectrum = plt.figure()\n",
    "axis = interacting_spectrum.add_subplot(111)\n",
    "plot_spectrum(lattice, eigenvalues, eigenfunctions, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful!  We can see a negative energy, decaying state, and some positive energy states.  Visually, the odd ones are clearly noninteracting and fit exactly in the box.  The even ones are shifted negatively in energy in comparison, and exhibit cusps at $x=0$, where the Dirac delta has support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum as a function of L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a little function to calculate the spectrum given the reduced mass $\\mu$, the interaction strength $g$, and the discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd_spectrum(mu, g, discretization, even_only=False, kinetic=None):\n",
    "    # Uniform discretization:\n",
    "    a = discretization[1] - discretization[0]\n",
    "    \n",
    "    if kinetic is None:\n",
    "        kinetic = T(mu)\n",
    "    H = hamiltonian(kinetic, V(dirac_delta(g, a)))\n",
    "    \n",
    "    eigenvalues, eigenfunctions = solve(H(discretization))\n",
    "    \n",
    "    if g == 0 or not even_only:\n",
    "        return eigenvalues, eigenfunctions\n",
    "    \n",
    "    if g > 0:\n",
    "        even_solutions = np.arange(0,eigenvalues.shape[0],2)\n",
    "    if g < 0:\n",
    "        even_solutions = np.append([0], np.arange(1,eigenvalues.shape[0],2))\n",
    "    \n",
    "    return eigenvalues[even_solutions], eigenfunctions[even_solutions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if this seems to be working by looking at how the energy levels change as a function of ring radius $L$.  We'll also show the noninteracting energies which (hopefully) should visually match the parity-odd eigenstates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mass = 1\n",
    "g = -4.215\n",
    "even_only = False\n",
    "trust = 12;  # How many states to trust, for a given volume?\n",
    "Ls = np.arange(0.5,2,0.025)\n",
    "\n",
    "if not even_only:\n",
    "    trust *= 2\n",
    "\n",
    "# Allocate a place to store results:\n",
    "eigenvalues = np.zeros([Ls.shape[0], trust])\n",
    "\n",
    "# Solve a bunch of times:\n",
    "for i in range(Ls.shape[0]):\n",
    "    lattice, spacing = uniform_discretization(256, Ls[i])\n",
    "    ev, ef = dd_spectrum(mass, g, lattice, even_only)\n",
    "    eigenvalues[i] = ev[0:trust]\n",
    "\n",
    "# Track the eigenenergies as they move with L\n",
    "for evs in eigenvalues.T:\n",
    "    plt.plot(Ls, evs)\n",
    "\n",
    "# Track the noninteracting energy levels\n",
    "for i in range(trust):\n",
    "    plt.plot(Ls, i**2 / (2 * mass * Ls**2) , color='black', linestyle='--')\n",
    "\n",
    "plt.ylim([min(-5,1.2*min(eigenvalues[:,0])),30])\n",
    "\n",
    "plt.xlabel('$L$')\n",
    "plt.ylabel('$E$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see good agreement between the noninteracting states and half the states, as predicted.  You can use the `even_only` flag of `dd_spectrum` to check which are the even and which are the odd states.  Since the chosen $g$ was negative, it's reassuring that the parity-even states are negatively shifted compared to the parity-odd states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see a tradeoff that can hinder real-world Lüscher-type analyses: at large $L$ the noninteracting states get very close to one another.  Then, the LQCD practitioner has to distinguish energy levels that are very close.  Since it's a stochastic method, this can be quite challenging.  In practice, we can only extract a few energy levels for a given center-of-mass momentum and box size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Lüscher's Finite Volume Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Fill in the function below so that it returns the value of the square of the scattering momentum, given the reduced mass $\\mu$ and the energy $E$.\n",
    "\n",
    "Ensure your function doesn't go crazy if you stick in a negative energy.  In that case, let it return a negative scattering momentum squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scattering_momentum_sq(mu, E):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Astoundingly, `numpy` doesn't have `arccot` or even `cot` built in (though `scipy` has them).  Fill in the functions below so that they give the cotangent and the principle inverse cotangent of a given value, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cot(theta):\n",
    "    return ...\n",
    "\n",
    "def arccot(x):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Fill in the function below so that it returns $\\cot(\\delta(k))$ given a ring radius $L$, reduced mass $\\mu$, and energy $E$.  DO NOT USE KNOWLEDGE OF $g$!  In other words, implement Lüscher's finite-volume formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cot_delta(L, mu, E):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Let $\\mu=2.3$ and $g=-4.215$.  These aren't some magic values, I just want everybody on the same page.\n",
    "\n",
    "Pick a variety of radii $L$ and some discretization.  Solve for the finite-volume spectrum for each.  Decide how many states to trust for each $L$.\n",
    "\n",
    "Transform triplets of $(L, \\mu, E)$ into pairs of $(k^2/\\mu^2, \\delta)$ and plot them over the known analytic result $\\delta = \\cot^{-1} \\frac{k}{\\mu g}$.  Recall that an attractive $\\delta$-function potential with strength $g$ has a bound state with energy $-\\frac{g^2\\mu}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2.3\n",
    "g = -4.215\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "1.  DOES IT LOOK RIGHT?\n",
    "2.  Can you tell which eigenenergies correspond to parity-even states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it looks right, congratulations!  You have successfully understood and implemented Lüscher's finite-volume formalism for one-dimensional quantum mechanics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "For a fixed $L$, how much do discretization effects matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "If you're feeling ambitious, implement an improved kinetic energy operator or two and see what you can do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_improved(mass, order):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "How does a bound state energy depends on the box size?  **Make sure you're not seeing discretization errors.**\n",
    "\n",
    "Try letting $N_x \\sim L^\\text{different integer powers}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Play!  Try other potentials.  Go crazy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
